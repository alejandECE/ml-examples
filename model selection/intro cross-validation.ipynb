{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis Alejandro (alejand@umich.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Hyper-parameters are parameters that are not directly learnt within estimators. It is possible and recommended to search the hyper-parameter space for the best cross validation score. \n",
    "\n",
    "If we tweak the hyperparameters using performance metrics on the test set, there is still a risk of overfitting since some knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. For this we can use an extra set called the \"validation set\".\n",
    "\n",
    "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "A solution to this problem is a procedure called cross-validation (CV for short). One of the most common used approaches is the k-fold cross-validation:\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "[Read More](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of k-fold cross-validation on a regression task\n",
    "Fits a [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) model to the bodyfat dataset and performs the cross validation mannually using the [Kfold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age (Years)', 'Weight (lbs)', 'Height (inches)',\n",
       "       'Neck circumference (cm)', 'Chest circumference (cm)',\n",
       "       'Abdomen 2 circumference (cm)', 'Hip circumference (cm)',\n",
       "       'Thigh circumference (cm)', 'Knee circunference (cm)',\n",
       "       'Ankle circunference (cm)', 'Biceps (extended) circunference (cm)',\n",
       "       'Forearm circunference (cm)', 'Wrist circunference (cm)', 'Bodyfat %'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "dataset = pd.read_csv('../../datasets/regression/bodyfat.csv')\n",
    "predictors = dataset.iloc[:,:-1].values\n",
    "responses = dataset.iloc[:,-1].values\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:  [0.73511561 0.38206664 0.70970376 0.68139746 0.81126304]\n",
      "Test Score (Best Model):  0.7011764698336852\n"
     ]
    }
   ],
   "source": [
    "# Splits into training/test sets\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors,responses,test_size = 0.2)\n",
    "# Train and evaluates model using standarization\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "# Defines model\n",
    "mdl = LinearRegression()\n",
    "# Performs K-fold cross-validation\n",
    "kf = KFold(n_splits = 5)\n",
    "score = np.zeros(kf.get_n_splits())\n",
    "best_score = -float(\"inf\")\n",
    "best_mdl = mdl\n",
    "best_sc = sc\n",
    "\n",
    "for i, indexes in enumerate(kf.split(X)):\n",
    "    # Sets\n",
    "    X_train = X[indexes[0],:]\n",
    "    y_train = y[indexes[0]]\n",
    "    X_test = X[indexes[1],:]\n",
    "    y_test = y[indexes[1]]\n",
    "    # Standarizing\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    # Training\n",
    "    mdl.fit(X_train,y_train)\n",
    "    y_pred = mdl.predict(X_test)    \n",
    "    score[i] = r2_score(y_test,y_pred)\n",
    "    # Picks best model\n",
    "    if best_score <= score[i]:\n",
    "        best_score = score[i]\n",
    "        best_mdl = mdl\n",
    "        best_sc = sc\n",
    "        \n",
    "print('Validation Scores: ', score)\n",
    "X_holdout = best_sc.transform(X_holdout)\n",
    "y_pred = best_mdl.predict(X_holdout)\n",
    "print('Test Score (Best Model): ', r2_score(y_holdout,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of leaking info\n",
    "Standarizing before doing the cross-validation process (training/testing) is a way to leak information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores:  [0.71418155 0.72363143 0.55877667 0.78066185 0.58456479]\n",
      "Test Score (Best Model):  0.7953924728102229\n"
     ]
    }
   ],
   "source": [
    "# Splits into training/test sets\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors,responses,test_size = 0.2)\n",
    "# Train and evaluates model using standarization\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "# Defines model\n",
    "mdl = LinearRegression()\n",
    "# Performs K-fold cross-validation\n",
    "kf = KFold(n_splits = 5)\n",
    "score = np.zeros(kf.get_n_splits())\n",
    "best_score = -float('inf')\n",
    "best_mdl = mdl\n",
    "best_sc = sc\n",
    "# Standarizing\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)\n",
    "X_holdout = sc.transform(X_holdout)\n",
    "\n",
    "for i, indexes in enumerate(kf.split(X)):\n",
    "    # Sets\n",
    "    X_train = X[indexes[0],:]\n",
    "    y_train = y[indexes[0]]\n",
    "    X_test = X[indexes[1],:]\n",
    "    y_test = y[indexes[1]]\n",
    "    # Training\n",
    "    mdl.fit(X_train,y_train)\n",
    "    y_pred = mdl.predict(X_test)    \n",
    "    score[i] = r2_score(y_test,y_pred)\n",
    "    # Picks best model\n",
    "    if best_score <= score[i]:\n",
    "        best_score = score[i]\n",
    "        best_mdl = mdl\n",
    "        \n",
    "print('Validation Scores: ', score)\n",
    "y_pred = best_mdl.predict(X_holdout)\n",
    "print('Test Score (Best Model): ', r2_score(y_holdout,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of k-fold cross-validation on a classification task\n",
    "Fits a [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model to the [breast cancer dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html). Performs cross-validation using the [cross-validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) function to be able to retrieve the best model and evaluate several metrics at once (see [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) as well). Since we need to apply standarization we are using a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_breast_cancer()\n",
    "print(dataset.feature_names, end=\"\\n\")\n",
    "print(dataset.target_names)\n",
    "predictors = dataset.data\n",
    "responses = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time training (Avg):  0.011170077323913574\n",
      "\n",
      "Training Metrics: \n",
      "Accuracy (Avg):  0.99\n",
      "F1 Macro (Avg):  0.99\n",
      "Recall Macro (Avg):  1.00\n",
      "Precision Macro (Avg):  0.98\n",
      "\n",
      "Validation Metrics: \n",
      "Accuracy (Avg):  0.97\n",
      "F1 Macro (Avg):  0.98\n",
      "Recall Macro (Avg):  0.99\n",
      "Precision Macro (Avg):  0.97\n",
      "\n",
      "Test Metrics: \n",
      "Accuracy:  0.97\n",
      "F1 Score:  0.98\n",
      "Recall:  0.97\n",
      "Precision:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Splits into training/test sets\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors,responses,test_size = 0.3, stratify=responses)\n",
    "# Defines model\n",
    "sc = StandardScaler()\n",
    "clf = LogisticRegression(penalty='l2', C = 1)\n",
    "estimators = [('normalizer', sc), ('classifier', clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "results = cross_validate(pipe,X,y,cv = 10,scoring = ['accuracy', 'f1','precision','recall'], n_jobs=-1,\n",
    "                         return_estimator=True, return_train_score=True)\n",
    "\n",
    "print('\\nTime training (Avg): ', results['fit_time'].mean())\n",
    "print('\\nTraining Metrics: ')\n",
    "print('Accuracy (Avg): ', '%.2f' % results['train_accuracy'].mean())\n",
    "print('F1 Macro (Avg): ', '%.2f' % results['train_f1'].mean())\n",
    "print('Recall Macro (Avg): ', '%.2f' % results['train_recall'].mean())\n",
    "print('Precision Macro (Avg): ', '%.2f' % results['train_precision'].mean())\n",
    "print('\\nValidation Metrics: ')\n",
    "print('Accuracy (Avg): ', '%.2f' % results['test_accuracy'].mean())\n",
    "print('F1 Macro (Avg): ', '%.2f' % results['test_f1'].mean())\n",
    "print('Recall Macro (Avg): ', '%.2f' % results['test_recall'].mean())\n",
    "print('Precision Macro (Avg): ', '%.2f' % results['test_precision'].mean())\n",
    "\n",
    "best_pipe = results['estimator'][results['test_accuracy'].argmax()]\n",
    "y_pred = best_pipe.predict(X_holdout)\n",
    "print('\\nTest Metrics: ')\n",
    "print('Accuracy: ', '%.2f' % accuracy_score(y_pred,y_holdout))\n",
    "print('F1 Score: ', '%.2f' % f1_score(y_pred,y_holdout))\n",
    "print('Recall: ', '%.2f' % recall_score(y_pred,y_holdout))\n",
    "print('Precision: ', '%.2f' % precision_score(y_pred,y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizer params:\n",
      "[1.41691369e+01 1.93214246e+01 9.22562849e+01 6.57615363e+02\n",
      " 9.60887430e-02 1.04714078e-01 8.80452765e-02 4.90608212e-02\n",
      " 1.81865922e-01 6.27250559e-02 4.02588827e-01 1.18449860e+00\n",
      " 2.85269330e+00 3.99662067e+01 6.97755866e-03 2.52388827e-02\n",
      " 3.04707933e-02 1.16045503e-02 2.04237039e-02 3.73709302e-03\n",
      " 1.63429581e+01 2.56681285e+01 1.07798966e+02 8.85823743e+02\n",
      " 1.32443771e-01 2.56749804e-01 2.71934676e-01 1.15178936e-01\n",
      " 2.91506145e-01 8.39630726e-02]\n",
      "[1.21953357e+01 2.04434379e+01 5.83070588e+02 1.19627675e+05\n",
      " 1.94433162e-04 2.84515582e-03 6.25187079e-03 1.49495275e-03\n",
      " 7.73518112e-04 5.11872367e-05 7.12924462e-02 2.85653498e-01\n",
      " 3.80842746e+00 1.93651226e+03 9.07798084e-06 2.99659682e-04\n",
      " 5.31585740e-04 3.47155915e-05 7.55772904e-05 6.34557359e-06\n",
      " 2.31736402e+01 3.97002208e+01 1.13246130e+03 3.20760171e+05\n",
      " 5.10650631e-04 2.45449894e-02 4.18269310e-02 4.23354560e-03\n",
      " 4.02422013e-03 3.16494699e-04]\n",
      "\n",
      "Classifier weights:\n",
      "[[-0.28694131 -0.3820251  -0.28393158 -0.39973934  0.04924369  0.39155797\n",
      "  -0.56910518 -0.57601796 -0.23794638  0.25381867 -1.26377758 -0.08410313\n",
      "  -0.69473228 -0.85984576  0.47810881  0.86623378 -0.03767147 -0.21532337\n",
      "   0.28638064  0.89014962 -0.83451438 -1.04402256 -0.69534332 -0.84967975\n",
      "  -0.63219584 -0.12792112 -0.55511379 -0.95135912 -0.68061335 -0.64793734]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nNormalizer params:')\n",
    "print(best_pipe['normalizer'].mean_)\n",
    "print(best_pipe['normalizer'].var_)\n",
    "print('\\nClassifier weights:')\n",
    "print(best_pipe['classifier'].coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
