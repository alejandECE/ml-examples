{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis A. Sanchez-Perez (alejand@umich.edu).\n",
    "<p><span style=\"color:green\"><b>Copyright &#169;</b> Do not distribute or use without authorization from author.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection of Elastic Nets\n",
    "Hyperparameter search for an Elastic Net classifier using [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset\n",
    "dataset = scipy.io.loadmat('E:/datasets/classification/ionosphere.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ionosphere dataset from the UCI machine learning repository:                   ',\n",
       "       'http://archive.ics.uci.edu/ml/datasets/Ionosphere                              ',\n",
       "       'X is a 351x34 real-valued matrix of predictors. Y is a categorical response:   ',\n",
       "       '\"b\" for bad radar returns and \"g\" for good radar returns.                      ',\n",
       "       'This is a binary classification problem.                                       '],\n",
       "      dtype='<U79')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints dataset description\n",
    "dataset['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares data for classification\n",
    "predictors = dataset['X'][:,2:] # the first two columns are useless\n",
    "positive = (dataset['Y'] == 'g').flatten()\n",
    "responses = np.zeros(predictors.shape[0])\n",
    "responses[positive] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits dataset into train/test\n",
    "X, X_holdout, y, y_holdout = train_test_split(predictors, responses, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('normalizer',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=300,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='elasticnet', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates pipeline\n",
    "clf = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=300)\n",
    "sc = StandardScaler()\n",
    "estimators = [('normalizer', sc), ('classifier', clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "Performs model selection of the following hyperparameters applied to the bank dataset (customers leaving):\n",
    "* C (Regularization)\n",
    "* L1/L2 Ratio\n",
    "\n",
    "This is perform using a [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines grid\n",
    "hyperparams = [{\n",
    "    'classifier__C': np.linspace(0.001, 1, 25),\n",
    "    'classifier__l1_ratio': np.linspace(0, 0.9, 10)\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 250 candidates, totalling 1250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1025 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1250 out of 1250 | elapsed:    4.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Performs grid search\n",
    "validator = GridSearchCV(pipe, cv=5, param_grid=hyperparams, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "results = validator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.878 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.209125, 'classifier__l1_ratio': 0.0}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.873 (std: 0.033)\n",
      "Parameters: {'classifier__C': 0.292375, 'classifier__l1_ratio': 0.0}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.873 (std: 0.030)\n",
      "Parameters: {'classifier__C': 0.1675, 'classifier__l1_ratio': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Report results\n",
    "utils.report_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects best configuration after search\n",
    "best = validator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('normalizer',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.209125, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=0.0, max_iter=300,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='elasticnet', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrains the model now on the available dataset (without validation/dev set). This step is optional!!!\n",
    "best.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Metrics): \n",
      "\n",
      "Accuracy: 0.91\n",
      "F1 Score: 0.90\n",
      "Recall: 0.89\n",
      "Precision: 0.92\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 66  16]\n",
      " [  5 158]]\n"
     ]
    }
   ],
   "source": [
    "# Training performance\n",
    "y_pred = best.predict(X)\n",
    "utils.report_classification(y, y_pred, avg='macro', title='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy: 0.86\n",
      "F1 Score: 0.85\n",
      "Recall: 0.83\n",
      "Precision: 0.89\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30 14]\n",
      " [ 1 61]]\n"
     ]
    }
   ],
   "source": [
    "# Holdout performance\n",
    "y_pred = best.predict(X_holdout)\n",
    "utils.report_classification(y_holdout, y_pred, avg='macro', title='Holdout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "Performs model selection of the following hyperparameters applied to the bank dataset (customers leaving):\n",
    "* C (Regularization)\n",
    "* L1/L2 Ratio\n",
    "\n",
    "This is perform using a [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines parameters distributions\n",
    "hyperparams_dist = [{\n",
    "    'classifier__C': scipy.stats.distributions.uniform(loc=0, scale=0.99), # uniform [0, 0.99]\n",
    "    'classifier__l1_ratio': scipy.stats.distributions.uniform(), # uniform [0, 1]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Performs randomized search\n",
    "validator = RandomizedSearchCV(pipe, cv=5, param_distributions=hyperparams,\n",
    "                               scoring='accuracy', n_jobs=-1, verbose=1, n_iter=20)\n",
    "results = validator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.873 (std: 0.030)\n",
      "Parameters: {'classifier__l1_ratio': 0.0, 'classifier__C': 0.1675}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.869 (std: 0.036)\n",
      "Parameters: {'classifier__l1_ratio': 0.0, 'classifier__C': 0.12587500000000001}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.865 (std: 0.036)\n",
      "Parameters: {'classifier__l1_ratio': 0.1, 'classifier__C': 0.875125}\n"
     ]
    }
   ],
   "source": [
    "# Report results\n",
    "utils.report_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects best configuration after search\n",
    "best = validator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('normalizer',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.1675, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=0.0, max_iter=300,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='elasticnet', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrains the model now on the available dataset (without validation/dev set). This step is optional!!!\n",
    "best.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Metrics): \n",
      "\n",
      "Accuracy: 0.91\n",
      "F1 Score: 0.89\n",
      "Recall: 0.88\n",
      "Precision: 0.91\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 65  17]\n",
      " [  6 157]]\n"
     ]
    }
   ],
   "source": [
    "# Training performance\n",
    "y_pred = best.predict(X)\n",
    "utils.report_classification(y, y_pred, avg='macro', title='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy: 0.86\n",
      "F1 Score: 0.85\n",
      "Recall: 0.83\n",
      "Precision: 0.89\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30 14]\n",
      " [ 1 61]]\n"
     ]
    }
   ],
   "source": [
    "# Holdout performance\n",
    "y_pred = best.predict(X_holdout)\n",
    "utils.report_classification(y_holdout, y_pred, avg='macro', title='Holdout')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
