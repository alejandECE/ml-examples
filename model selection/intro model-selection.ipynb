{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis Alejandro (alejand@umich.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Model selection is choosing between different complexity or flexibility to fit/explain your data.\n",
    "#### Complexity Controlling Parameters\n",
    "* Not used to fit the data\n",
    "* Usually called \"hyperparameters\" (i.e., in Bayesian models parameters of the prior for instance)\n",
    "\n",
    "#### Selecting best complexity parameters\n",
    "Selecting the best complexity parameters usually consist of exploring different combinations of the hyperparameters to explain your data. More technically this search consist of:\n",
    "* An estimator (regressor or classifier )\n",
    "* A parameter space\n",
    "* A method for searching or sampling candidates\n",
    "* A cross-validation scheme\n",
    "* A score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.reports as rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1\n",
    "Performs model selection of the following hyperparameters applied to the bank dataset (customers leaving):\n",
    "* Penalty (l1 or l2)\n",
    "* C (Inverse of regularization)\n",
    "\n",
    "This is perform using cross-validation and a grid search using [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads dataset from file\n",
    "dataset = pd.read_csv('../../datasets/classification/bank_exiting.csv')\n",
    "predictors = dataset.iloc[:,3:-1].values\n",
    "responses = dataset.iloc[:,-1].values\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female' 'Male']\n",
      "[608 'Spain' 'Female' 41 1 83807.86 1 0 1 112542.58]\n",
      "[608 'Spain' 0 41 1 83807.86 1 0 1 112542.58]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the gender feature\n",
    "print(dataset['Gender'].unique())\n",
    "print(predictors[1,:])\n",
    "encoder = LabelEncoder()\n",
    "predictors[:,2] = encoder.fit_transform(predictors[:,2]) # only 0 or 1 after this (just one column needed)\n",
    "print(predictors[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[608 'Spain' 0 41 1 83807.86 1 0 1 112542.58]\n",
      "[0.0 1.0 608 0 41 1 83807.86 1 0 1 112542.58]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the country feature\n",
    "print(predictors[1,:])\n",
    "ct = ColumnTransformer([('country_category', OneHotEncoder(categories='auto', drop='first'),[1])], remainder='passthrough')\n",
    "predictors = ct.fit_transform(predictors)\n",
    "print(predictors[1,:])\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors, responses, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5397174116277985, -0.9499994057663559, -1.040467106253047,\n",
       "       -1.231796281195587, 0.8108355785714346, 1.1671011270196134, 0.0,\n",
       "       0.0, 0, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This step should not be here since we will leak info into the validation sets!!!\n",
    "ct = ColumnTransformer([('normalizer', StandardScaler(),[2,4,5,6,7,10])],remainder='passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "X_holdout = ct.transform(X_holdout)\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  1.8673037000000001  seconds\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.811 (std: 0.002)\n",
      "Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.810 (std: 0.002)\n",
      "Parameters: {'C': 0.2, 'penalty': 'l2'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.809 (std: 0.002)\n",
      "Parameters: {'C': 0.5, 'penalty': 'l2'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Performs grid search\n",
    "start = time.perf_counter()\n",
    "C_choices = [0.0001, 0.1, 0.2, 0.5, 0.7, 1]\n",
    "penalty_choices = ['l1','l2']\n",
    "\n",
    "hyperparams = [{\n",
    "    'penalty': penalty_choices,\n",
    "    'C': C_choices\n",
    "}]\n",
    "\n",
    "mdl = LogisticRegression(max_iter=200)\n",
    "validator = GridSearchCV(mdl, cv=3, param_grid=hyperparams, scoring='accuracy', n_jobs=-1,verbose = 1)\n",
    "validator.fit(X,y)\n",
    "end = time.perf_counter()\n",
    "print('Elapsed time: ', end - start, ' seconds\\n')\n",
    "rp.report_grid_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy:  0.80\n",
      "F1 Score:  0.31\n",
      "Recall:  0.21\n",
      "Precision:  0.58\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1523   63]\n",
      " [ 328   86]]\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation in the holdout set\n",
    "y_pred = validator.predict(X_holdout)\n",
    "rp.report_classification(y_holdout,y_pred,title='Holdout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "Performs model selection of the following hyperparameters applied to the wine dataset:\n",
    "* Penalty (l1 or l2)\n",
    "* C (Inverse of regularization)\n",
    "* Max # of iterations\n",
    "\n",
    "This is perform using cross-validation and a grid search using [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Notice that no standarization is applied in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_wine()\n",
    "predictors = dataset.data\n",
    "responses = dataset.target\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors, responses, test_size = 0.2,stratify=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  0.9235902999999999  seconds\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.950 (std: 0.028)\n",
      "Parameters: {'C': 0.7, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.950 (std: 0.028)\n",
      "Parameters: {'C': 0.7, 'max_iter': 300, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.950 (std: 0.028)\n",
      "Parameters: {'C': 1, 'max_iter': 300, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.8s finished\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Performs grid search\n",
    "start = time.perf_counter()\n",
    "C_choices = [0.0001, 0.1, 0.2, 0.5, 0.7, 1]\n",
    "iter_choices = [10, 20, 50, 100, 300]\n",
    "\n",
    "hyperparams = [{\n",
    "    'penalty': ['l1'],\n",
    "    'C': C_choices,\n",
    "    'max_iter': iter_choices,\n",
    "    'solver': ['saga']\n",
    "},    \n",
    "{\n",
    "    'penalty': ['l2'],\n",
    "    'C': C_choices,\n",
    "    'max_iter': iter_choices,\n",
    "    'solver': ['lbfgs']\n",
    "}]\n",
    "\n",
    "mdl = LogisticRegression(multi_class='multinomial')\n",
    "validator = GridSearchCV(mdl, cv=5, param_grid=hyperparams, scoring='accuracy', n_jobs=-1,verbose = 1,iid = False)\n",
    "validator.fit(X,y)\n",
    "end = time.perf_counter()\n",
    "print('Elapsed time: ', end - start, ' seconds\\n')\n",
    "rp.report_grid_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy:  0.97\n",
      "F1 Score:  0.97\n",
      "Recall:  0.97\n",
      "Precision:  0.98\n",
      "\n",
      "Confusion Matrix:\n",
      " [[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  1  9]]\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation in the holdout set\n",
    "y_pred = validator.predict(X_holdout)\n",
    "rp.report_classification(y_holdout,y_pred,avg='macro',title='Holdout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3\n",
    "Performs model selection of the following hyperparameters applied to the wine dataset:\n",
    "* Penalty (l1 or l2)\n",
    "* C (Inverse of regularization)\n",
    "* Max # of iterations\n",
    "\n",
    "This is perform using cross-validation and a grid search using [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Since we want to apply standarization, we must use a [Pipeline](https://scikit-learn.org/stable/modules/compose.html#pipeline) to correctly standarize and evaluate the models during the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_wine()\n",
    "predictors = dataset.data\n",
    "responses = dataset.target\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors, responses, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  0.6007431999999993  seconds\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.5, 'classifier__max_iter': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.5, 'classifier__max_iter': 20, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.5, 'classifier__max_iter': 50, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.5, 'classifier__max_iter': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.5, 'classifier__max_iter': 300, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.7, 'classifier__max_iter': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.7, 'classifier__max_iter': 300, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.017)\n",
      "Parameters: {'classifier__C': 1, 'classifier__max_iter': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.1, 'classifier__max_iter': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.1, 'classifier__max_iter': 20, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.1, 'classifier__max_iter': 50, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.1, 'classifier__max_iter': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.1, 'classifier__max_iter': 300, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.2, 'classifier__max_iter': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.2, 'classifier__max_iter': 20, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.2, 'classifier__max_iter': 50, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.2, 'classifier__max_iter': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 0.2, 'classifier__max_iter': 300, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 277 out of 300 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Performs grid search\n",
    "start = time.perf_counter()\n",
    "\n",
    "sc = StandardScaler()\n",
    "clf = LogisticRegression(multi_class='ovr')\n",
    "estimators = [('normalizer', sc), ('classifier', clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "C_choices = [0.0001, 0.1, 0.2, 0.5, 0.7, 1]\n",
    "iter_choices = [10, 20, 50, 100, 300]\n",
    "\n",
    "\n",
    "hyperparams = [{\n",
    "    'classifier__penalty': ['l1'],\n",
    "    'classifier__C': C_choices,\n",
    "    'classifier__max_iter': iter_choices,\n",
    "    'classifier__solver': ['saga']\n",
    "},    \n",
    "{\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__C': C_choices,\n",
    "    'classifier__max_iter': iter_choices,\n",
    "    'classifier__solver': ['lbfgs']\n",
    "}]\n",
    "\n",
    "validator = GridSearchCV(pipe, cv=5, param_grid=hyperparams, scoring='accuracy', n_jobs=-1,verbose = 1,iid = False)\n",
    "validator.fit(X,y)\n",
    "end = time.perf_counter()\n",
    "print('Elapsed time: ', end - start, ' seconds\\n')\n",
    "rp.report_grid_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy:  1.00\n",
      "F1 Score:  1.00\n",
      "Recall:  1.00\n",
      "Precision:  1.00\n",
      "\n",
      "Confusion Matrix:\n",
      " [[14  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation in the holdout set\n",
    "y_pred = validator.predict(X_holdout)\n",
    "rp.report_classification(y_holdout,y_pred,avg='macro',title='Holdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
