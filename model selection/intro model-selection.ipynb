{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis A. Sanchez-Perez (alejand@umich.edu).\n",
    "<p><span style=\"color:green\"><b>Copyright &#169;</b> Do not distribute or use without authorization from author.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Model selection is choosing between different complexity or flexibility to fit/explain your data.\n",
    "#### Complexity Controlling Parameters\n",
    "* Not used to fit the data\n",
    "* Usually called \"hyperparameters\" (i.e., in Bayesian models parameters of the prior for instance)\n",
    "\n",
    "#### Selecting best complexity parameters\n",
    "Selecting the best complexity parameters usually consist of exploring different combinations of the hyperparameters to explain your data. More technically this search consist of:\n",
    "* An estimator (regressor or classifier )\n",
    "* A parameter space\n",
    "* A method for searching or sampling candidates\n",
    "* A cross-validation scheme\n",
    "* A score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1\n",
    "Performs model selection of the following hyperparameters applied to the bank dataset (customers leaving):\n",
    "* Penalty (l1 or l2)\n",
    "* C (Inverse of regularization)\n",
    "\n",
    "This is perform using a [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads dataset from file\n",
    "dataset = pd.read_csv('E:/datasets/classification/bank_exiting.csv')\n",
    "predictors = dataset.iloc[:,3:-1].values\n",
    "responses = dataset.iloc[:,-1].values\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female' 'Male']\n",
      "[608 'Spain' 'Female' 41 1 83807.86 1 0 1 112542.58]\n",
      "[608 'Spain' 0 41 1 83807.86 1 0 1 112542.58]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the gender feature\n",
    "print(dataset['Gender'].unique())\n",
    "print(predictors[1,:])\n",
    "encoder = LabelEncoder()\n",
    "predictors[:,2] = encoder.fit_transform(predictors[:,2]) # only 0 or 1 after this (just one column needed)\n",
    "print(predictors[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[608 'Spain' 0 41 1 83807.86 1 0 1 112542.58]\n",
      "[0.0 1.0 608 0 41 1 83807.86 1 0 1 112542.58]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the country feature\n",
    "print(predictors[1,:])\n",
    "ct = ColumnTransformer([('country_category', OneHotEncoder(categories='auto', drop='first'),[1])], remainder='passthrough')\n",
    "predictors = ct.fit_transform(predictors)\n",
    "print(predictors[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits intro training/holdout\n",
    "X, X_holdout, y, y_holdout = train_test_split(predictors, responses, test_size=0.2, stratify=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6636522716407491, -1.2306938563643364, -0.3437761243945,\n",
       "       0.414489509180079, -0.910289944180706, 0.7869945564393298, 1.0,\n",
       "       0.0, 1, 1, 1], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This step should not be here since we will leak info into the validation sets!!!\n",
    "ct = ColumnTransformer([('normalizer', StandardScaler(), [2,4,5,6,7,10])], remainder='passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "X_holdout = ct.transform(X_holdout)\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.306 (std: 0.019)\n",
      "Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.305 (std: 0.019)\n",
      "Parameters: {'C': 0.7, 'penalty': 'l2'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.305 (std: 0.018)\n",
      "Parameters: {'C': 0.5, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  32 out of  36 | elapsed:    1.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Defines grid\n",
    "C_choices = [0.0001, 0.1, 0.2, 0.5, 0.7, 1]\n",
    "penalty_choices = ['l1','l2']\n",
    "hyperparams = [{\n",
    "    'penalty': penalty_choices,\n",
    "    'C': C_choices\n",
    "}]\n",
    "# Defines model\n",
    "mdl = LogisticRegression(max_iter=200)\n",
    "# Performs grid search using CV\n",
    "validator = GridSearchCV(mdl, cv=3, param_grid=hyperparams, scoring='f1', n_jobs=-1, verbose=2)\n",
    "validator.fit(X,y)\n",
    "utils.report_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects best configuration after search\n",
    "best = validator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrains the model now on the available dataset (without validation/dev set). This step is optional!!!\n",
    "best.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Metrics): \n",
      "\n",
      "Accuracy: 0.81\n",
      "F1 Score: 0.31\n",
      "Recall: 0.21\n",
      "Precision: 0.60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6138  232]\n",
      " [1288  342]]\n"
     ]
    }
   ],
   "source": [
    "# Training performance\n",
    "y_pred = best.predict(X)\n",
    "utils.report_classification(y, y_pred, title='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy: 0.81\n",
      "F1 Score: 0.33\n",
      "Recall: 0.23\n",
      "Precision: 0.59\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1528   65]\n",
      " [ 314   93]]\n"
     ]
    }
   ],
   "source": [
    "# Holdout performance\n",
    "y_pred = best.predict(X_holdout)\n",
    "utils.report_classification(y_holdout, y_pred, title='Holdout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "Performs model selection of the following hyperparameters applied to the wine dataset:\n",
    "* Penalty (l1 or l2)\n",
    "* C (Inverse of regularization)\n",
    "* Max # of iterations\n",
    "\n",
    "This is perform using a [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Notice that no standarization is applied in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_wine()\n",
    "predictors = dataset.data\n",
    "responses = dataset.target\n",
    "X, X_holdout, y, y_holdout = train_test_split(predictors, responses, test_size=0.2, stratify=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.944 (std: 0.028)\n",
      "Parameters: {'C': 1, 'max_iter': 300, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.944 (std: 0.028)\n",
      "Parameters: {'C': 0.7, 'max_iter': 300, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.944 (std: 0.028)\n",
      "Parameters: {'C': 0.5, 'max_iter': 300, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Defines grid\n",
    "C_choices = [0.0001, 0.1, 0.2, 0.5, 0.7, 1]\n",
    "iter_choices = [10, 20, 50, 100, 300]\n",
    "hyperparams = [{\n",
    "    'penalty': ['l1'],\n",
    "    'C': C_choices,\n",
    "    'max_iter': iter_choices,\n",
    "    'solver': ['saga']\n",
    "},    \n",
    "{\n",
    "    'penalty': ['l2'],\n",
    "    'C': C_choices,\n",
    "    'max_iter': iter_choices,\n",
    "    'solver': ['lbfgs']\n",
    "}]\n",
    "# Defines model\n",
    "mdl = LogisticRegression(multi_class='multinomial')\n",
    "# Performs grid search\n",
    "validator = GridSearchCV(mdl, cv=5, param_grid=hyperparams, scoring='f1_macro', n_jobs=-1, verbose=2)\n",
    "validator.fit(X,y)\n",
    "utils.report_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects best configuration after search\n",
    "best = validator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=300,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrains the model now on the available dataset (without validation/dev set). This step is optional!!!\n",
    "best.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Metrics): \n",
      "\n",
      "Accuracy: 0.96\n",
      "F1 Score: 0.97\n",
      "Recall: 0.97\n",
      "Precision: 0.97\n",
      "\n",
      "Confusion Matrix:\n",
      " [[45  2  0]\n",
      " [ 1 55  1]\n",
      " [ 0  1 37]]\n"
     ]
    }
   ],
   "source": [
    "# Training performance\n",
    "y_pred = best.predict(X)\n",
    "utils.report_classification(y, y_pred, avg='macro', title='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy: 1.00\n",
      "F1 Score: 1.00\n",
      "Recall: 1.00\n",
      "Precision: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      " [[12  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Holdout performance\n",
    "y_pred = best.predict(X_holdout)\n",
    "utils.report_classification(y_holdout, y_pred, avg='macro', title='Holdout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3\n",
    "Performs model selection of the following hyperparameters applied to the wine dataset:\n",
    "* Penalty (l1 or l2)\n",
    "* C (Inverse of regularization)\n",
    "* Max # of iterations\n",
    "\n",
    "This is perform using a [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Since we want to apply standarization, we must use a [Pipeline](https://scikit-learn.org/stable/modules/compose.html#pipeline) to correctly standarize and evaluate the models during the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_wine()\n",
    "predictors = dataset.data\n",
    "responses = dataset.target\n",
    "X, X_holdout, y, y_holdout = train_test_split(predictors, responses, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 1, 'classifier__max_iter': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.986 (std: 0.029)\n",
      "Parameters: {'classifier__C': 1, 'classifier__max_iter': 20, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.979 (std: 0.028)\n",
      "Parameters: {'classifier__C': 1, 'classifier__max_iter': 300, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Defines pipeline\n",
    "sc = StandardScaler()\n",
    "clf = LogisticRegression(multi_class='ovr')\n",
    "estimators = [('normalizer', sc), ('classifier', clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "# Defines grid\n",
    "C_choices = [0.0001, 0.1, 0.2, 0.5, 0.7, 1]\n",
    "hyperparams = [{\n",
    "    'classifier__penalty': ['l1'],\n",
    "    'classifier__C': C_choices,\n",
    "    'classifier__max_iter': iter_choices,\n",
    "    'classifier__solver': ['saga']\n",
    "},    \n",
    "{\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__C': C_choices,\n",
    "    'classifier__max_iter': iter_choices,\n",
    "    'classifier__solver': ['lbfgs']\n",
    "}]\n",
    "# Performs grid search using CV\n",
    "validator = GridSearchCV(pipe, cv=5, param_grid=hyperparams, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "validator.fit(X,y)\n",
    "utils.report_search(validator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects best configuration after search\n",
    "best = validator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('normalizer',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=10,\n",
       "                                    multi_class='ovr', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrains the model now on the available dataset (without validation/dev set). This step is optional!!!\n",
    "best.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Metrics): \n",
      "\n",
      "Accuracy: 1.00\n",
      "F1 Score: 1.00\n",
      "Recall: 1.00\n",
      "Precision: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48  0  0]\n",
      " [ 0 53  0]\n",
      " [ 0  0 41]]\n"
     ]
    }
   ],
   "source": [
    "# Training performance\n",
    "y_pred = best.predict(X)\n",
    "utils.report_classification(y, y_pred, avg='macro', title='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout (Metrics): \n",
      "\n",
      "Accuracy: 0.97\n",
      "F1 Score: 0.98\n",
      "Recall: 0.98\n",
      "Precision: 0.97\n",
      "\n",
      "Confusion Matrix:\n",
      " [[11  0  0]\n",
      " [ 1 17  0]\n",
      " [ 0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "# Holdout performance\n",
    "y_pred = best.predict(X_holdout)\n",
    "utils.report_classification(y_holdout, y_pred, avg='macro', title='Holdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
