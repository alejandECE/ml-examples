{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis A. Sanchez-Perez (alejand@umich.edu).\n",
    "<p><span style=\"color:green\"><b>Copyright &#169;</b> Do not distribute or use without authorization from author.</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset\n",
    "dataset = sio.loadmat('../../datasets/classification/emails.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'you', 'for', 'that']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [element[0] for element in dataset['vocab'][0]]\n",
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3000x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 338915 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset['X']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['Y'].ravel()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'you', 'for', 'that', 'this', 'your', 'with', 'are', 'from']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First email content (only showing first 10 words)\n",
    "email = ([vocab[i] for i,value in enumerate(X[:,0]) if value])\n",
    "email[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X[X > 0] = 1\n",
    "# Splitting the dataset into the training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = BernoulliNB()\n",
    "mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1487    9]\n",
      " [  78  676]]\n",
      "0.9613333333333334\n"
     ]
    }
   ],
   "source": [
    "# Predicting the training set results\n",
    "y_pred = mdl.predict(X_train)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[497   7]\n",
      " [ 38 208]]\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = mdl.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_email(url, vocab):\n",
    "    corpus = dict(zip(vocab, np.zeros(len(vocab))))\n",
    "    with open(url,'r') as fid:\n",
    "        text = fid.read()\n",
    "#         print('Email: ', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z\\'\\s]',' ',text)\n",
    "#         print('Preprocessed email: ', text)\n",
    "        for word in text.split():\n",
    "            if word in corpus:\n",
    "                corpus[word] = 1\n",
    "            else:\n",
    "                print('Word', '\"{}\"'.format(word), 'not in dictionary')\n",
    "        arr = np.array([corpus[element] for element in vocab])\n",
    "        print('List of words in arr:', [vocab[i] for i, value in enumerate(arr) if value])\n",
    "    return arr.reshape(1,len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word \"i\" not in dictionary\n",
      "Word \"if\" not in dictionary\n",
      "Word \"be\" not in dictionary\n",
      "Word \"aviable\" not in dictionary\n",
      "Word \"to\" not in dictionary\n",
      "Word \"wednesday\" not in dictionary\n",
      "Word \"i\" not in dictionary\n",
      "Word \"we\" not in dictionary\n",
      "Word \"i\" not in dictionary\n",
      "Word \"to\" not in dictionary\n",
      "Word \"i\" not in dictionary\n",
      "List of words in arr: ['the', 'you', 'that', 'your', 'are', 'have', 'but', 'was', 'time', 'would', 'some', 'over', 'going', 'come', 'hours', 'current', 'questions', 'office', 'during', 'kind', 'normal', 'regards', 'meet', 'hello', 'class', 'material', 'regarding', 'wondering', 'professor']\n"
     ]
    }
   ],
   "source": [
    "arr = load_email('../../datasets/classification/email1.txt', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.predict(arr.reshape(1,len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99998365e-01, 1.63517072e-06]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.predict_proba(arr.reshape(1,len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
