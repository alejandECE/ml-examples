{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis Alejandro (alejand@umich.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Feature Sensitivity to Posterior Probability (FSPP)\n",
    "Computes a wrapper feature ranking especifically designed for MLP neural networks using the algorithm proposed by:\n",
    "\n",
    "https://ieeexplore.ieee.org/abstract/document/5282531\n",
    "\n",
    "and briefly compares to Mutual Information (MI) raking criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.feature_selection.fspp import get_fspp\n",
    "from utils.feature_selection.mutual import MutualInfo\n",
    "from utils.feature_selection.mutualI import MutualInfoI\n",
    "from utils.feature_selection.reports import report_feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_breast_cancer()\n",
    "print(dataset.feature_names, end=\"\\n\")\n",
    "print(dataset.target_names)\n",
    "predictors = dataset.data\n",
    "responses = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits into training/test sets\n",
    "X,X_holdout,y,y_holdout = train_test_split(predictors,responses,\n",
    "                                           test_size = 0.3,\n",
    "                                           random_state = 0,\n",
    "                                           stratify=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time training (Avg):  0.21363577842712403\n",
      "\n",
      "Training Metrics: \n",
      "Accuracy (Avg):  0.99\n",
      "\n",
      "Validation Metrics: \n",
      "Accuracy (Avg):  0.98\n",
      "\n",
      "Test Metrics: \n",
      "Accuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Defines model\n",
    "sc = StandardScaler()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(30))\n",
    "estimators = [('normalizer', sc), ('classifier', clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "results = cross_validate(pipe,X,y,cv = 5,scoring = ['accuracy'], n_jobs=-1,\n",
    "                         return_estimator=True, return_train_score=True)\n",
    "print('\\nTime training (Avg): ', results['fit_time'].mean())\n",
    "print('\\nTraining Metrics: ')\n",
    "print('Accuracy (Avg): ', '%.2f' % results['train_accuracy'].mean())\n",
    "print('\\nValidation Metrics: ')\n",
    "print('Accuracy (Avg): ', '%.2f' % results['test_accuracy'].mean())\n",
    "\n",
    "best_pipe = results['estimator'][results['test_accuracy'].argmin()]\n",
    "y_pred = best_pipe.predict(X_holdout)\n",
    "print('\\nTest Metrics: ')\n",
    "print('Accuracy: ', '%.2f' % accuracy_score(y_pred,y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranked 1 is (worst texture) with value 0.066886\n",
      "Feature ranked 2 is (mean perimeter) with value 0.053913\n",
      "Feature ranked 3 is (mean radius) with value 0.047033\n",
      "Feature ranked 4 is (worst symmetry) with value 0.044616\n",
      "Feature ranked 5 is (worst smoothness) with value 0.042552\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is (compactness error) with value 0.011899\n",
      "Feature ranked 27 is (perimeter error) with value 0.010737\n",
      "Feature ranked 28 is (mean area) with value 0.009811\n",
      "Feature ranked 29 is (mean compactness) with value 0.007259\n",
      "Feature ranked 30 is (worst fractal dimension) with value 0.007106\n"
     ]
    }
   ],
   "source": [
    "rank = get_fspp(best_pipe,X)\n",
    "report_feature_ranking(rank,dataset.feature_names,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallel version\n",
      "Feature ranked 1 is (worst perimeter) with value 0.708011\n",
      "Feature ranked 2 is (worst radius) with value 0.685644\n",
      "Feature ranked 3 is (worst concave points) with value 0.667807\n",
      "Feature ranked 4 is (mean concave points) with value 0.658822\n",
      "Feature ranked 5 is (worst area) with value 0.638709\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is (mean fractal dimension) with value 0.077595\n",
      "Feature ranked 27 is (fractal dimension error) with value 0.072675\n",
      "Feature ranked 28 is (symmetry error) with value 0.048220\n",
      "Feature ranked 29 is (texture error) with value 0.035799\n",
      "Feature ranked 30 is (smoothness error) with value 0.032073\n"
     ]
    }
   ],
   "source": [
    "mi = MutualInfo(X,y,n_jobs=-1)\n",
    "rank = mi.compute()\n",
    "report_feature_ranking(rank,dataset.feature_names,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallel version\n",
      "Feature ranked 1 is (worst perimeter) with value 0.203446\n",
      "Feature ranked 2 is (worst radius) with value 0.181079\n",
      "Feature ranked 3 is (worst concave points) with value 0.163241\n",
      "Feature ranked 4 is (mean concave points) with value 0.154257\n",
      "Feature ranked 5 is (worst area) with value 0.134144\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is (mean fractal dimension) with value -0.426971\n",
      "Feature ranked 27 is (fractal dimension error) with value -0.431890\n",
      "Feature ranked 28 is (symmetry error) with value -0.456345\n",
      "Feature ranked 29 is (texture error) with value -0.468767\n",
      "Feature ranked 30 is (smoothness error) with value -0.472493\n"
     ]
    }
   ],
   "source": [
    "mi = MutualInfoI(X,y,n_jobs=-1)\n",
    "rank = mi.compute()\n",
    "report_feature_ranking(rank,dataset.feature_names,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
