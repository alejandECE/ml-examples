{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis A. Sanchez-Perez (alejand@umich.edu).\n",
    "<p><span style=\"color:green\"><b>Copyright &#169;</b> Do not distribute or use without authorization from author.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Feature Sensitivity to Posterior Probability (FSPP)\n",
    "Computes a wrapper feature ranking especifically designed for MLP neural networks using the algorithm proposed in\n",
    "https://ieeexplore.ieee.org/abstract/document/5282531\n",
    "and briefly compares to Mutual Information (MI) raking criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from utils.fspp import get_fspp\n",
    "from utils.mutual import MutualInfo\n",
    "from utils.mutualI import MutualInfoI\n",
    "from utils.reports import report_feature_ranking\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.load_breast_cancer()\n",
    "print(dataset.feature_names, end=\"\\n\")\n",
    "print(dataset.target_names)\n",
    "predictors = dataset.data\n",
    "responses = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits into training/test sets\n",
    "X, X_holdout, y, y_holdout = train_test_split(predictors, responses, test_size=0.3, stratify=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time training (Avg): 0.187815523147583\n",
      "\n",
      "Training Metrics: \n",
      "Accuracy (Avg): 0.99\n",
      "\n",
      "Validation Metrics:\n",
      "Accuracy (Avg): 0.97\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Defines model\n",
    "sc = StandardScaler()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(30))\n",
    "estimators = [('normalizer', sc), ('classifier', clf)]\n",
    "pipe = Pipeline(estimators)\n",
    "results = cross_validate(pipe, X, y, cv = 5, scoring = ['accuracy'], n_jobs=-1,\n",
    "                         return_estimator=True, return_train_score=True)\n",
    "print('\\nTime training (Avg):', results['fit_time'].mean())\n",
    "print('\\nTraining Metrics: ')\n",
    "print('Accuracy (Avg):', '%.2f' % results['train_accuracy'].mean())\n",
    "print('\\nValidation Metrics:')\n",
    "print('Accuracy (Avg):', '%.2f' % results['test_accuracy'].mean())\n",
    "best_pipe = results['estimator'][results['test_accuracy'].argmin()]\n",
    "y_pred = best_pipe.predict(X_holdout)\n",
    "print('\\nTest Metrics:')\n",
    "print('Accuracy:', '%.2f' % accuracy_score(y_pred,y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elpased time: 0.01784449999999982\n",
      "\n",
      "Feature ranked 1 is 'worst smoothness' with value 6.01E-02\n",
      "Feature ranked 2 is 'worst symmetry' with value 5.02E-02\n",
      "Feature ranked 3 is 'worst concavity' with value 4.85E-02\n",
      "Feature ranked 4 is 'mean concavity' with value 4.59E-02\n",
      "Feature ranked 5 is 'mean texture' with value 4.29E-02\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is 'symmetry error' with value 8.09E-03\n",
      "Feature ranked 27 is 'smoothness error' with value 6.80E-03\n",
      "Feature ranked 28 is 'worst fractal dimension' with value 6.48E-03\n",
      "Feature ranked 29 is 'concave points error' with value 5.75E-03\n",
      "Feature ranked 30 is 'texture error' with value 4.58E-03\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "rank = get_fspp(best_pipe, X)\n",
    "print('Elpased time:', time.perf_counter() - start, end='\\n\\n')\n",
    "report_feature_ranking(rank, dataset.feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallel version\n",
      "Elpased time: 3.7993387000000003\n",
      "\n",
      "Feature ranked 1 is 'worst perimeter' with value 7.00E-01\n",
      "Feature ranked 2 is 'worst radius' with value 6.54E-01\n",
      "Feature ranked 3 is 'worst concave points' with value 6.45E-01\n",
      "Feature ranked 4 is 'worst area' with value 6.21E-01\n",
      "Feature ranked 5 is 'mean concave points' with value 6.11E-01\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is 'mean fractal dimension' with value 6.62E-02\n",
      "Feature ranked 27 is 'symmetry error' with value 6.36E-02\n",
      "Feature ranked 28 is 'fractal dimension error' with value 5.01E-02\n",
      "Feature ranked 29 is 'texture error' with value 3.51E-02\n",
      "Feature ranked 30 is 'smoothness error' with value 3.42E-02\n"
     ]
    }
   ],
   "source": [
    "mi = MutualInfo(X,y,n_jobs=-1) \n",
    "start = time.perf_counter()\n",
    "rank = mi.compute()\n",
    "print('Elpased time:', time.perf_counter() - start, end='\\n\\n')\n",
    "report_feature_ranking(rank,dataset.feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallel version\n",
      "Elpased time: 11.5133717\n",
      "\n",
      "Feature ranked 1 is 'worst perimeter' with value 1.92E-01\n",
      "Feature ranked 2 is 'worst radius' with value 1.46E-01\n",
      "Feature ranked 3 is 'worst concave points' with value 1.37E-01\n",
      "Feature ranked 4 is 'worst area' with value 1.13E-01\n",
      "Feature ranked 5 is 'mean concave points' with value 1.03E-01\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 26 is 'mean fractal dimension' with value -4.42E-01\n",
      "Feature ranked 27 is 'symmetry error' with value -4.44E-01\n",
      "Feature ranked 28 is 'fractal dimension error' with value -4.58E-01\n",
      "Feature ranked 29 is 'texture error' with value -4.73E-01\n",
      "Feature ranked 30 is 'smoothness error' with value -4.74E-01\n"
     ]
    }
   ],
   "source": [
    "mi = MutualInfoI(X,y,n_jobs=-1)\n",
    "start = time.perf_counter()\n",
    "rank = mi.compute()\n",
    "print('Elpased time:', time.perf_counter() - start, end='\\n\\n')\n",
    "report_feature_ranking(rank, dataset.feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
