{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Created by Luis Alejandro (alejand@umich.edu)\n",
    "Applies the Mutual Information (MI) ranking criterion to the text emotions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.nlp.vectorizer import Vectorizer\n",
    "from utils.feature_selection.mutual import MutualInfo\n",
    "from utils.feature_selection.reports import report_feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'boredom' 'empty' 'enthusiasm' 'fun' 'happiness' 'hate' 'love'\n",
      " 'neutral' 'relief' 'sadness' 'surprise' 'worry']\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('../../datasets/classification/text_emotions/train_data.csv')\n",
    "corpus = dataset.iloc[:,1].values\n",
    "responses = dataset.iloc[:,0].values\n",
    "print(np.unique(responses))\n",
    "lc = LabelEncoder()\n",
    "responses = lc.fit_transform(responses)\n",
    "min_freq = 20\n",
    "max_freq = 10000\n",
    "# Conditioning text and generates dictionary of word\n",
    "dictionary = dict()\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = corpus[i].lower()\n",
    "    corpus[i] = re.sub(r'[^a-z\\'\\s]',' ',corpus[i])\n",
    "    corpus[i] = re.sub(r'[^a-z]+[\\']|[\\'][^a-z]+',' ',corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_custom (corpus):\n",
    "    start = time.perf_counter()\n",
    "    # ------------------------------------------------------\n",
    "    cv = Vectorizer(corpus,min_freq=min_freq,max_freq=max_freq)\n",
    "    X = cv.fit()\n",
    "    # ------------------------------------------------------   \n",
    "    end = time.perf_counter()\n",
    "    print(end - start, ' seconds')\n",
    "\n",
    "    # Converts matrix to nparray\n",
    "    X = X.toarray()\n",
    "    \n",
    "    # Outputs validation\n",
    "    cv.output_validation()\n",
    "    \n",
    "    return X,cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the features using built-in funciton in sklearn\n",
    "def extract_features_sklearn (corpus):\n",
    "    start = time.perf_counter()\n",
    "    # ------------------------------------------------------\n",
    "    cv = CountVectorizer(min_df = min_freq + 1, max_df = max_freq - 1)\n",
    "    X = cv.fit_transform(corpus)\n",
    "    # ------------------------------------------------------   \n",
    "    end = time.perf_counter()\n",
    "    print(end - start, ' seconds')\n",
    "\n",
    "    # Converts matrix to nparray\n",
    "    X = X.toarray()\n",
    "\n",
    "    # Verifies data matrix\n",
    "    print(sum(X[0,:]))\n",
    "    print(corpus[0])\n",
    "    \n",
    "    return X,cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39993029999999985  seconds\n",
      "11\n",
      " tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part   \n",
      "(30000, 1579)\n",
      "0.3602251000000001  seconds\n",
      "143\n",
      "item: achieving a new appreciation on how a xml build script can really be painful and cumbersome\n",
      "column: [ 13 139  15 115 356 327  46 520   4]\n",
      "data: [2 1 1 1 1 1 1 1 1]\n",
      "a\n",
      "new\n",
      "on\n",
      "how\n",
      "can\n",
      "really\n",
      "be\n",
      "painful\n",
      "and\n",
      "(30000, 1640)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test sets\n",
    "predictors,cv = extract_features_sklearn(corpus)\n",
    "print(predictors.shape)\n",
    "predictors,cv = extract_features_custom(corpus)\n",
    "print(predictors.shape)\n",
    "predictors_filtered = predictors\n",
    "#predictors_filtered[predictors_filtered > 1] = 1\n",
    "X, X_holdout, y, y_holdout = train_test_split(predictors_filtered,responses,test_size = 0.20,stratify=responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parallel version\n",
      "3.2090814  seconds\n"
     ]
    }
   ],
   "source": [
    "# Computes MI with custom implementation\n",
    "start = time.perf_counter()\n",
    "mi = MutualInfo(X,y,n_jobs=4)\n",
    "mi.compute()\n",
    "end = time.perf_counter()\n",
    "print(end - start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranked 1 is (love) with value 0.029847\n",
      "Feature ranked 2 is (sad) with value 0.019956\n",
      "Feature ranked 3 is (hate) with value 0.018577\n",
      "Feature ranked 4 is (happy) with value 0.011805\n",
      "Feature ranked 5 is (thanks) with value 0.010093\n",
      "Feature ranked 6 is (miss) with value 0.009972\n",
      "Feature ranked 7 is (good) with value 0.008407\n",
      "Feature ranked 8 is (sorry) with value 0.008406\n",
      "Feature ranked 9 is (you) with value 0.008103\n",
      "Feature ranked 10 is (my) with value 0.007829\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 1631 is (drink) with value 0.000150\n",
      "Feature ranked 1632 is (living) with value 0.000148\n",
      "Feature ranked 1633 is (wanting) with value 0.000132\n",
      "Feature ranked 1634 is (action) with value 0.000130\n",
      "Feature ranked 1635 is (thursday) with value 0.000124\n",
      "Feature ranked 1636 is (article) with value 0.000120\n",
      "Feature ranked 1637 is (sent) with value 0.000117\n",
      "Feature ranked 1638 is (camera) with value 0.000109\n",
      "Feature ranked 1639 is (street) with value 0.000107\n",
      "Feature ranked 1640 is (decided) with value 0.000101\n"
     ]
    }
   ],
   "source": [
    "# Reports result\n",
    "report_feature_ranking(mi.info, cv.words, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elpased time: 309.67578210000005\n"
     ]
    }
   ],
   "source": [
    "# Computes MI with sklearn implementation\n",
    "start = time.perf_counter()\n",
    "mi = mutual_info_classif(X,y)\n",
    "end = time.perf_counter()\n",
    "print('Elpased time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranked 1 is (sad) with value 0.016675\n",
      "Feature ranked 2 is (hate) with value 0.016635\n",
      "Feature ranked 3 is (love) with value 0.015798\n",
      "Feature ranked 4 is (bye) with value 0.013701\n",
      "Feature ranked 5 is (thats) with value 0.012516\n",
      "Feature ranked 6 is (pay) with value 0.012277\n",
      "Feature ranked 7 is (always) with value 0.012038\n",
      "Feature ranked 8 is (breakfast) with value 0.011655\n",
      "Feature ranked 9 is (stupid) with value 0.011629\n",
      "Feature ranked 10 is (out) with value 0.011206\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "Feature ranked 1631 is (chinese) with value 0.000000\n",
      "Feature ranked 1632 is (parents) with value 0.000000\n",
      "Feature ranked 1633 is (raining) with value 0.000000\n",
      "Feature ranked 1634 is (videos) with value 0.000000\n",
      "Feature ranked 1635 is (j) with value 0.000000\n",
      "Feature ranked 1636 is (happens) with value 0.000000\n",
      "Feature ranked 1637 is (lived) with value 0.000000\n",
      "Feature ranked 1638 is (yours) with value 0.000000\n",
      "Feature ranked 1639 is (cd) with value 0.000000\n",
      "Feature ranked 1640 is (know) with value 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Reports result\n",
    "report_feature_ranking(mi, cv.words, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
